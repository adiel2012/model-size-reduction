{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# âœ‚ï¸ Model Pruning From Scratch: Sparsity and Significance\n",
    "\n",
    "[![\"Open In Colab\"](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/adiel2012/model-size-reduction/blob/main/pruning_demo.ipynb)\n",
    "\n",
    "## ðŸ“– The Theory: Magnitude-based Pruning\n",
    "\n",
    "Neural networks are often **over-parameterized**, meaning many weights contribute very little to the final result. Pruning is the process of zeroing out these insignificant weights.\n",
    "\n",
    "### L1 Magnitude Pruning\n",
    "The most common heuristic is that weights with the smallest absolute values (L1 norm) are the least important. By setting them to zero, we create a **sparse matrix**.\n",
    "\n",
    "### Masking\n",
    "In practice, we don't just delete the weight. We maintain a binary **mask** $M$ of the same shape as $W$. The effective weight used in the model is then:\n",
    "\n",
    "$$W_{pruned} = W \\odot M$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "def manual_l1_pruning(weight, amount=0.3):\n",
    "    \"\"\"\n",
    "    Implementation of L1 Unstructured Pruning from scratch.\n",
    "    weight: Tensor\n",
    "    amount: Fraction of weights to prune (0.0 to 1.0)\n",
    "    \"\"\"\n",
    "    # 1. Flatten weight and compute L1 magnitude\n",
    "    w_abs = torch.abs(weight).flatten()\n",
    "    \n",
    "    # 2. Find the threshold value for the bottom % of weights\n",
    "    k = int(amount * w_abs.numel())\n",
    "    if k == 0: return weight, torch.ones_like(weight)\n",
    "    \n",
    "    threshold = torch.kthvalue(w_abs, k).values\n",
    "    \n",
    "    # 3. Create Binary Mask (1 if > threshold, 0 otherwise)\n",
    "    mask = (torch.abs(weight) > threshold).float()\n",
    "    \n",
    "    # 4. Apply Mask\n",
    "    return weight * mask, mask\n",
    "\n",
    "# Test on GPT-2 Layer\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "layer_weight = model.transformer.h[0].attn.c_attn.weight.data.clone()\n",
    "\n",
    "pruned_w, mask = manual_l1_pruning(layer_weight, amount=0.5)\n",
    "\n",
    "print(f\"Original Params: {layer_weight.numel()}\")\n",
    "print(f\"Zeroed Params:   {torch.sum(mask == 0).item()}\")\n",
    "print(f\"Sparsity:        {100. * torch.sum(mask == 0).item() / layer_weight.numel():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## ðŸ”¢ Worked Example with numbers\n\nA step-by-step trace of `manual_l1_pruning` with a tiny weight matrix so you can verify every value by hand.\n\n- Weight matrix **2 Ã— 5**, pruning **30 %** of weights (`amount = 0.3`)\n- 10 total weights â†’ **k = 3** weights will be zeroed out",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import torch\n\n# 2Ã—5 weight matrix (10 elements total)\nweight = torch.tensor([[ 0.9,  0.2,  0.6,  0.1,  0.5],\n                        [ 0.8,  0.3,  0.7, 0.05,  0.4]])   # shape [2, 5]\n\namount = 0.3   # prune the 30 % smallest-magnitude weights\n\n# â”€â”€ Step 1 : Flatten and compute |weight| â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nw_abs = torch.abs(weight).flatten()\n# w_abs  =>  [0.9, 0.2, 0.6, 0.1, 0.5, 0.8, 0.3, 0.7, 0.05, 0.4]\n\n# â”€â”€ Step 2 : Find the pruning threshold â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nk = int(amount * w_abs.numel())   # => int(0.3 Ã— 10) = 3\n# Sorted ascending: [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n#                     ^1    ^2   ^3   â† 3rd-smallest is the threshold\nthreshold = torch.kthvalue(w_abs, k).values   # => 0.2\n\n# â”€â”€ Step 3 : Build the binary mask  (1 = keep, 0 = prune) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# |weight|:   [[0.9, 0.2, 0.6, 0.1, 0.5],  [0.8, 0.3, 0.7, 0.05, 0.4]]\n# > 0.2 :     [[  1,   0,   1,   0,   1],   [  1,   1,   1,    0,   1]]\nmask = (torch.abs(weight) > threshold).float()\n# mask        =>  [[1., 0., 1., 0., 1.],\n#                  [1., 1., 1., 0., 1.]]\n\n# â”€â”€ Step 4 : Apply mask  (element-wise multiply) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\npruned_weight = weight * mask\n# weight Ã— mask:\n#   [[ 0.9Ã—1,  0.2Ã—0,  0.6Ã—1,  0.1Ã—0,  0.5Ã—1],\n#    [ 0.8Ã—1,  0.3Ã—1,  0.7Ã—1, 0.05Ã—0,  0.4Ã—1]]\n# pruned_weight  =>  [[ 0.9,  0.0,  0.6,  0.0,  0.5],\n#                     [ 0.8,  0.3,  0.7,  0.0,  0.4]]\n\nzeroed   = int(torch.sum(mask == 0).item())        # => 3  (0.2, 0.1, 0.05 were zeroed)\nsparsity = 100.0 * zeroed / weight.numel()         # => 3 / 10 Ã— 100 = 30.0 %\n\nprint(f\"k (weights to prune) : {k}\")               # => 3\nprint(f\"Threshold            : {threshold:.2f}\")   # => 0.20\nprint(f\"Mask :\\n{mask}\")\n# => [[1., 0., 1., 0., 1.],\n#     [1., 1., 1., 0., 1.]]\nprint(f\"Pruned weight :\\n{pruned_weight}\")\n# => [[ 0.9000,  0.0000,  0.6000,  0.0000,  0.5000],\n#     [ 0.8000,  0.3000,  0.7000,  0.0000,  0.4000]]\nprint(f\"Zeroed params        : {zeroed} / {weight.numel()}\")   # => 3 / 10\nprint(f\"Sparsity             : {sparsity:.1f}%\")               # => 30.0%",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§± Structured vs. Unstructured\n",
    "While the code above prunes individual weights (**Unstructured**), modern hardware often prefers pruning entire rows or columns (**Structured**) to achieve real-world latency gains."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}