{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# âœ‚ï¸ Model Pruning From Scratch: Sparsity and Significance\n",
                "\n",
                "[![\"Open In Colab\"](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/adiel2012/model-size-reduction/blob/main/pruning_demo.ipynb)\n",
                "\n",
                "## ðŸ“– The Theory: Magnitude-based Pruning\n",
                "\n",
                "Neural networks are often **over-parameterized**, meaning many weights contribute very little to the final result. Pruning is the process of zeroing out these insignificant weights.\n",
                "\n",
                "### L1 Magnitude Pruning\n",
                "The most common heuristic is that weights with the smallest absolute values (L1 norm) are the least important. By setting them to zero, we create a **sparse matrix**.\n",
                "\n",
                "### Masking\n",
                "In practice, we don't just delete the weight. We maintain a binary **mask** $M$ of the same shape as $W$. The effective weight used in the model is then:\n",
                "\n",
                "$$W_{pruned} = W \\odot M$$\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "from transformers import GPT2LMHeadModel\n",
                "\n",
                "def manual_l1_pruning(weight, amount=0.3):\n",
                "    \"\"\"\n",
                "    Implementation of L1 Unstructured Pruning from scratch.\n",
                "    weight: Tensor\n",
                "    amount: Fraction of weights to prune (0.0 to 1.0)\n",
                "    \"\"\"\n",
                "    # 1. Flatten weight and compute L1 magnitude\n",
                "    w_abs = torch.abs(weight).flatten()\n",
                "    \n",
                "    # 2. Find the threshold value for the bottom % of weights\n",
                "    k = int(amount * w_abs.numel())\n",
                "    if k == 0: return weight, torch.ones_like(weight)\n",
                "    \n",
                "    threshold = torch.kthvalue(w_abs, k).values\n",
                "    \n",
                "    # 3. Create Binary Mask (1 if > threshold, 0 otherwise)\n",
                "    mask = (torch.abs(weight) > threshold).float()\n",
                "    \n",
                "    # 4. Apply Mask\n",
                "    return weight * mask, mask\n",
                "\n",
                "# Test on GPT-2 Layer\n",
                "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
                "layer_weight = model.transformer.h[0].attn.c_attn.weight.data.clone()\n",
                "\n",
                "pruned_w, mask = manual_l1_pruning(layer_weight, amount=0.5)\n",
                "\n",
                "print(f\"Original Params: {layer_weight.numel()}\")\n",
                "print(f\"Zeroed Params:   {torch.sum(mask == 0).item()}\")\n",
                "print(f\"Sparsity:        {100. * torch.sum(mask == 0).item() / layer_weight.numel():.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ§± Structured vs. Unstructured\n",
                "While the code above prunes individual weights (**Unstructured**), modern hardware often prefers pruning entire rows or columns (**Structured**) to achieve real-world latency gains."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}